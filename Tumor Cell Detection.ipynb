{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Machine_learning_Assignment_2_Partha_Pratim_Saha_218047874.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSRaUk_ZlxF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0_1FOHtlxF7",
        "colab_type": "text"
      },
      "source": [
        "# Task A (1.1)\n",
        "#Read the Training and Testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-8oP92khlxF9",
        "colab_type": "code",
        "colab": {},
        "outputId": "b704166e-349c-4f43-ceb0-81ec6aaab1e1"
      },
      "source": [
        "# Task A (1.1)\n",
        "#Read the Training and Testing data\n",
        "Train = pd.read_csv('train_wbcd.csv', delimiter=',')\n",
        "Test = pd.read_csv('test_wbcd.csv', delimiter=',')\n",
        "print(\"Test shape: {}\".format(Test.shape))\n",
        "print(\"Train shape: {}\".format(Train.shape))\n",
        "\n",
        "print(\"The number of features in Training Data: {}\".format(Train.shape[1]-2))\n",
        "print(\"The number of features in Testing Data: {}\".format(Test.shape[1]-2))\n",
        "#Train data has 100 rows and 32 columns\n",
        "#Test data has 20 rows and 32 columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test shape: (20, 32)\n",
            "Train shape: (100, 32)\n",
            "The number of features in Training Data: 30\n",
            "The number of features in Testing Data: 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyFtZXp1lxGD",
        "colab_type": "text"
      },
      "source": [
        "# Total Number of 0 and 1 in train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05zIV05tlxGE",
        "colab_type": "code",
        "colab": {},
        "outputId": "d3b63a9a-2a0e-44ae-abe6-9eb776c856c7"
      },
      "source": [
        "#Total number of 0 and 1 for label train data\n",
        "Train=Train.replace('B',0)\n",
        "Train=Train.replace('M',1)\n",
        "Train['Diagnosis'].value_counts()\n",
        "#Replacing B as 0 and M as 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    58\n",
              "1    42\n",
              "Name: Diagnosis, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osp3_oyFlxGI",
        "colab_type": "code",
        "colab": {},
        "outputId": "96b5b78a-f0c5-4271-9223-9788167bf68c"
      },
      "source": [
        "plt.hist(Train['Diagnosis'])\n",
        "#The Training data is balanced. There's not much difference between 0 and 1."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([58.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 42.]),\n",
              " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 266
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIo-ixjulxGN",
        "colab_type": "code",
        "colab": {},
        "outputId": "82c9be39-d651-468f-81c8-d0a51347e462"
      },
      "source": [
        "#Total number of 0 and 1 for label test data\n",
        "Test=Test.replace('B',0)\n",
        "Test=Test.replace('M',1)\n",
        "Test['Diagnosis'].value_counts()\n",
        "#Replacing B as 0 and M as 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    14\n",
              "1     6\n",
              "Name: Diagnosis, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dfJSmc1lxGR",
        "colab_type": "code",
        "colab": {},
        "outputId": "e4cbb0de-24ec-45cb-e656-0a664da6bd95"
      },
      "source": [
        "plt.hist(Test['Diagnosis'])\n",
        "#The data is highly unbalanced between 0 and 1. 1 seems much low in comparison to 0. So, the data is not balanced."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([14.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  6.]),\n",
              " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUHgh75alxGV",
        "colab_type": "text"
      },
      "source": [
        "# Finding the missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfFf2C19lxGW",
        "colab_type": "code",
        "colab": {},
        "outputId": "ff1978d1-446a-4220-baee-67334e9665e4"
      },
      "source": [
        "#Missing value columns for Train Data\n",
        "Missing_value_count_by_column_Train=Train.isnull().sum()\n",
        "print(Missing_value_count_by_column_Train[Missing_value_count_by_column_Train >0])\n",
        "# In f21 column of training data there is two missing value."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f21    2\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzjheInLlxGa",
        "colab_type": "code",
        "colab": {},
        "outputId": "103f549b-ea4c-4aaf-f2c2-16c60faeee65"
      },
      "source": [
        "#Missing value Columns for Test Data\n",
        "Missing_value_count_by_column_Test=Test.isnull().sum()\n",
        "print(Missing_value_count_by_column_Test[Missing_value_count_by_column_Test >0])\n",
        "#In f21 column of testing data there is one missing value."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f21    1\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_Sq01wIlxGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Replace Missing values with median\n",
        "meadian_value_Train=Train['f21'].median()\n",
        "Train['f21']=Train['f21'].fillna(meadian_value_Train)\n",
        "\n",
        "meadian_value_Test=Test['f21'].median()\n",
        "Test['f21']=Test['f21'].fillna(meadian_value_Test)\n",
        "#For training and testing data the value is replaced using the median"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoSFoqqLlxGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalization with maximum-minimum/(maximum-minimum)\n",
        "\n",
        "Norm_Train = Train.iloc[:,2:]\n",
        "Train.iloc[:,2:] = (Norm_Train - Norm_Train.min()) / (Norm_Train.max() - Norm_Train.min())\n",
        "\n",
        "Norm_Test = Test.iloc[:,2:]\n",
        "Test.iloc[:,2:] = (Norm_Test - Norm_Test.min()) / (Norm_Test.max() - Norm_Test.min())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sB5N3sVlxGn",
        "colab_type": "text"
      },
      "source": [
        "# 1.2 Logistic Regression Train Logistic regression models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Ggzhmm91lxGo",
        "colab_type": "code",
        "colab": {},
        "outputId": "77444919-99a6-455b-98ba-9e7ee9beba34"
      },
      "source": [
        "#Logistic regression using Lambda as 0.1\n",
        "Dtrain =Train\n",
        "Dtest = Test\n",
        "predictors = ['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10','f11','f12','f13','f14','f15','f16','f17','f18','f19','f20','f21','f22','f23','f24','f25','f26','f27','f28','f29','f30']\n",
        "response = ['Diagnosis']\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "lambda_val = 0.1\n",
        "#Initialize the Logitic regression model with l2 penalty\n",
        "lr_with_lambda = LogisticRegression(C=1/lambda_val, penalty='l2')\n",
        "lr_with_lambda.fit(Dtrain[predictors], Dtrain['Diagnosis'])\n",
        "y_predict_with_lambda = lr_with_lambda.predict(Dtest[predictors])\n",
        "\n",
        "#Evaluate our model\n",
        "model_acc_with_lambda = accuracy_score(y_predict_with_lambda, Dtest['Diagnosis'])\n",
        "model_precision_with_lambda= precision_score(y_predict_with_lambda, Dtest['Diagnosis'])\n",
        "model_F1_score_with_lambda= f1_score(y_predict_with_lambda, Dtest['Diagnosis'])\n",
        "model_confusion_matrix_with_lambda= confusion_matrix(y_predict_with_lambda, Dtest['Diagnosis'])\n",
        "print(\"Model Accuracy with lambda is: {}\".format(model_acc))\n",
        "print(\"Model Precision with lambda is:{}\".format(model_precision))\n",
        "print(\"Model F1_score with lambda is:{}\".format(model_F1_score))\n",
        "print(\"Model confusion_matrix with lambda is:\\n{}\".format(model_confusion_matrix))\n",
        "\n",
        "#The accuracy seems better but in terms of precision it's not good. Its prediciting more false positive\n",
        "# In the accuracy matrix false positive seems high\n",
        "#The F1 score is the weighted average of accuracy and precision. So,it shows slightly better result."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Accuracy with lambda is: 0.95\n",
            "Model Precision with lambda is:0.3333333333333333\n",
            "Model F1_score with lambda is:0.5\n",
            "Model confusion_matrix with lambda is:\n",
            "[[14  4]\n",
            " [ 0  2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXzsN3M9lxGs",
        "colab_type": "code",
        "colab": {},
        "outputId": "26087215-bd28-497b-b3b8-47c29bec3b9e"
      },
      "source": [
        "#Logistic regression using alpha 0.1\n",
        "Dtrain =Train\n",
        "Dtest = Test\n",
        "predictors = ['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10','f11','f12','f13','f14','f15','f16','f17','f18','f19','f20','f21','f22','f23','f24','f25','f26','f27','f28','f29','f30']\n",
        "response = ['Diagnosis']\n",
        "alpha_val = 0.1\n",
        "#Initialize the Logitic regression model with l2 penalty\n",
        "lr_with_alpha = LogisticRegression(C=1/alpha_val, penalty='l1')\n",
        "lr_with_alpha.fit(Dtrain[predictors], Dtrain['Diagnosis'])\n",
        "y_predict_with_alpha = lr_with_alpha.predict(Dtest[predictors])\n",
        "\n",
        "#Evaluate our model\n",
        "model_acc_with_alpha = accuracy_score(y_predict_with_alpha, Dtest['Diagnosis'])\n",
        "model_precision_with_alpha= precision_score(y_predict_with_alpha, Dtest['Diagnosis'])\n",
        "model_F1_score_with_alpha= f1_score(y_predict_with_alpha, Dtest['Diagnosis'])\n",
        "model_confusion_matrix_with_alpha= confusion_matrix(y_predict_with_alpha, Dtest['Diagnosis'])\n",
        "print(\"Model Accuracy with alpha: {}\".format(model_acc))\n",
        "print(\"Model Precision with alpha:{}\".format(model_precision))\n",
        "print(\"Model F1_score with aplpha:{}\".format(model_F1_score))\n",
        "print(\"Model confusion_matrix with alpha:\\n{}\".format(model_confusion_matrix))\n",
        "#The accuracy seems better but precision score is not good.\n",
        "# In the accuracy matrix false positive seems high\n",
        "#The F1 score is the weighted average of accuracy and precision. So,it shows slightly better result."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Accuracy with alpha: 0.95\n",
            "Model Precision with alpha:0.3333333333333333\n",
            "Model F1_score with aplpha:0.5\n",
            "Model confusion_matrix with alpha:\n",
            "[[14  4]\n",
            " [ 0  2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_f3kg-OlxGw",
        "colab_type": "code",
        "colab": {},
        "outputId": "b90b87a2-9d7f-4208-d710-cec4c89752e6"
      },
      "source": [
        "#Logistc regression using alpha 0.1 and lambda 0.1\n",
        "Dtrain =Train\n",
        "Dtest = Test\n",
        "predictors = ['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10','f11','f12','f13','f14','f15','f16','f17','f18','f19','f20','f21','f22','f23','f24','f25','f26','f27','f28','f29','f30']\n",
        "response = ['Diagnosis']\n",
        "alpha_val = 0.1\n",
        "enet_B = SGDClassifier(loss='log', penalty='elasticnet', alpha=alpha_val, l1_ratio=0.5, max_iter=1000) \n",
        "enet_B.fit(Dtrain[predictors], Dtrain[response].values.reshape((Dtrain[response].shape[0],)))\n",
        "y_predict_B = enet_B.predict(Dtest[predictors])\n",
        "enet_acc = accuracy_score(y_predict_B, Dtest[response])\n",
        "model_precision= precision_score(y_predict_B, Dtest['Diagnosis'])\n",
        "model_F1_score= f1_score(y_predict_B, Dtest['Diagnosis'])\n",
        "model_confusion_matrix= confusion_matrix(y_predict_B, Dtest['Diagnosis'])\n",
        "print(\"Model accuracy with alpha 0.1 and lambda 0.1: {}\".format(enet_acc))\n",
        "print(\"Model Precision with alpha 0.1 and lambda 0.1:{}\".format(model_precision))\n",
        "print(\"Model F1_score with alpha 0.1 and lambda 0.1:{}\".format(model_F1_score))\n",
        "print(\"Model confusion_matrix with alpha 0.1 and lambda 0.1:\\n{}\".format(model_confusion_matrix))\n",
        "#when we use alpha and lambda together the precision provides better result from before that's why the F1 score is also increased \n",
        "#But from the confusion matrix it seems that it's providing more false positive that's why accuracy score came down"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model accuracy with alpha 0.1 and lambda 0.1: 0.85\n",
            "Model Precision with alpha 0.1 and lambda 0.1:0.5\n",
            "Model F1_score with alpha 0.1 and lambda 0.1:0.6666666666666666\n",
            "Model confusion_matrix with alpha 0.1 and lambda 0.1:\n",
            "[[14  3]\n",
            " [ 0  3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "881CaX0UlxG0",
        "colab_type": "text"
      },
      "source": [
        "# 1.3 Choosing the best hyper-parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8yOyi6QlxG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Choosing the best hyper parameter\n",
        "Dtrain =Train\n",
        "Dtest = Test\n",
        "predictors = ['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10','f11','f12','f13','f14','f15','f16','f17','f18','f19','f20','f21','f22','f23','f24','f25','f26','f27','f28','f29','f30']\n",
        "response = ['Diagnosis']\n",
        "from sklearn.model_selection import train_test_split\n",
        "def runLRmodel(trials, data, predictors, label, penalty_type, penalty_score):\n",
        "\n",
        "   model_acc     = 0\n",
        "   model_weights = np.zeros([1,3])\n",
        "   \n",
        "   for i in range(0,trials):\n",
        "      Dtrain, Dtest = train_test_split(data, test_size=0.3)\n",
        "      lr = LogisticRegression(C=1/penalty_score, penalty=penalty_type)\n",
        "      lr.fit(Dtrain[predictors], Dtrain[label])\n",
        "      y_predict = lr.predict(Dtest[predictors])\n",
        "      model_acc += accuracy_score(y_predict, Dtest[label])\n",
        "          \n",
        "   model_acc /= trials\n",
        "\n",
        "\n",
        "   return np.round(model_acc, decimals=2), np.round(model_weights,decimals=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMkYYMSGlxG5",
        "colab_type": "code",
        "colab": {},
        "outputId": "4736e697-8c30-44bf-b801-0ec36f319699"
      },
      "source": [
        "#Best Lambda\n",
        "lambda_vals = [.01,.03,.1,.3,1,3,10,33,.001,.003,]\n",
        "l2_acc = np.zeros(len(lambda_vals))\n",
        "index = 0\n",
        "#L2 regularization\n",
        "for l in lambda_vals:\n",
        "   l2_acc[index], w = runLRmodel(100,Train, predictors, 'Diagnosis', 'l2', np.float(l))\n",
        "   index += 1\n",
        "\n",
        "\n",
        "print(\"Acc: {}\".format(l2_acc))\n",
        "\n",
        "# penalty at which validation accuracy is maximum\n",
        "max_index_l2  = np.argmax(l2_acc)\n",
        " \n",
        "best_lambda = lambda_vals[max_index_l2]\n",
        "\n",
        "print(\"Best Lambda: {}\".format(best_lambda))\n",
        "#the best lambda is 0.001,o .03 and .01 as all provides the best accuracy result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: [0.98 0.98 0.98 0.96 0.95 0.93 0.91 0.85 0.99 0.98]\n",
            "Best Lambda: 0.001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sij9xBSWlxG9",
        "colab_type": "code",
        "colab": {},
        "outputId": "3d3e15f7-3b6b-405b-a98a-70e501552586"
      },
      "source": [
        "#Best Alpha\n",
        "alpha_vals = [0.1,1,3,10,33,100,333,1000,3333,10000,33333]\n",
        "l1_acc = np.zeros(len(alpha_vals))\n",
        "index = 0\n",
        "#L2 regularization\n",
        "for l in alpha_vals:\n",
        "   l1_acc[index], w = runLRmodel(100,Train, predictors, 'Diagnosis', 'l1', np.float(l))\n",
        "   index += 1\n",
        "\n",
        "print(\"Acc: {}\".format(l1_acc))\n",
        "# penalty at which validation accuracy is maximum\n",
        "max_index_l1  = np.argmax(l1_acc)\n",
        "best_alpha = alpha_vals[max_index_l1]\n",
        "print(\"Best Alpha: {}\".format(best_alpha))\n",
        "#The best alpha value is 0.1 as it provides the best accuracy result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: [0.96 0.94 0.91 0.91 0.89 0.89 0.89 0.43 0.41 0.45 0.58]\n",
            "Best Alpha: 0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfZX15NXlxHA",
        "colab_type": "code",
        "colab": {},
        "outputId": "d9fe3741-af37-4f22-d4e1-b6b4c915088f"
      },
      "source": [
        "#Logistc regression using alpha 0.1 and lambda 0.1\n",
        "from sklearn.linear_model import SGDClassifier \n",
        "Dtrain =Train\n",
        "Dtest = Test\n",
        "predictors = ['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10','f11','f12','f13','f14','f15','f16','f17','f18','f19','f20','f21','f22','f23','f24','f25','f26','f27','f28','f29','f30']\n",
        "response = ['Diagnosis']\n",
        "\n",
        "\n",
        "alpha_val = 0.1\n",
        "\n",
        "enet = SGDClassifier(loss='log', penalty='elasticnet', alpha=alpha_val, l1_ratio=.50, max_iter=1000) \n",
        "enet.fit(Dtrain[predictors], Dtrain[response].values.reshape((Dtrain[response].shape[0],)))\n",
        "y_predict = enet.predict(Dtest[predictors])\n",
        "enet_acc = accuracy_score(y_predict, Dtest[response])\n",
        "model_precision= precision_score(y_predict, Dtest['Diagnosis'])\n",
        "model_confusion_matrix= confusion_matrix(y_predict, Dtest['Diagnosis'])\n",
        "print(\"Acc: {}\".format(enet_acc))\n",
        "print(\"Model Precision is:{}\".format(model_precision))\n",
        "print(\"Model confusion_matrix is:{}\".format(model_confusion_matrix))\n",
        "\n",
        "#top five feature selection in decreasing order\n",
        "\n",
        "feature_weights_lambda=enet.coef_[0]\n",
        "Weight_matrix_lambda = pd.DataFrame()\n",
        "Weight_matrix_lambda['Feature'] = pd.Series(predictors)\n",
        "Weight_matrix_lambda['Weights'] = pd.Series(feature_weights_lambda,name= \"Weights\")\n",
        "Weight_matrix_lambda['Abs Weights'] = abs(Weight_matrix_lambda['Weights'])\n",
        "a = np.sort(Weight_matrix_lambda['Abs Weights'])[::-1]\n",
        "print(\"Top five features are:{}\".format(a[:5]))\n",
        "# alpha value and lambda value are used as 0.5. the accuracy is 85% as it provides some false positive result \n",
        "#The precision is also not good.\n",
        "#It seems a overfitting model as the accuracy level comes down from before."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: 0.85\n",
            "Model Precision is:0.5\n",
            "Model confusion_matrix is:[[14  3]\n",
            " [ 0  3]]\n",
            "Top five features are:[0.50081288 0.31740226 0.31321656 0.23262087 0.20295856]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMdjk5kalxHE",
        "colab_type": "text"
      },
      "source": [
        "# TASK B 2.1-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Z3GmO632lxHF",
        "colab_type": "code",
        "colab": {},
        "outputId": "09bef0aa-a981-4d6a-ddb1-6e1390b4448c"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "minist = pd.read_csv('reduced_mnist.csv', delimiter=',')\n",
        "\n",
        "print(\"The number of features for Minist are: {}\".format(minist.shape[1]-1))\n",
        "\n",
        "\n",
        "\n",
        "#print the unique labels in y\n",
        "y=minist['label']\n",
        "print (\"unique labels: {}\".format(np.unique(y)))\n",
        "\n",
        "#the number of rows\n",
        "Count_Row=minist.shape[0]\n",
        "print(\"the number of rows are: {}\".format(Count_Row))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of features for Minist are: 784\n",
            "unique labels: [0 1 2 3 4 5 6 7 8 9]\n",
            "the number of rows are: 2520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVcO-NjelxHJ",
        "colab_type": "text"
      },
      "source": [
        "# TASK B 2.1-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij0_v3JFlxHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "Label=minist['label']\n",
        "Pexil=minist.loc[:,'pixel0':'pixel783']\n",
        "\n",
        "#split\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(Pexil, Label, test_size=0.3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MBtdaHdlxHO",
        "colab_type": "code",
        "colab": {},
        "outputId": "f955dab9-a1d1-4288-f1ae-5d7034693308"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier \n",
        "from sklearn import datasets\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn import datasets\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier \n",
        "\n",
        "alpha_val = 1\n",
        "\n",
        "OVR = OneVsRestClassifier(LogisticRegression(penalty='l1',C = 1/alpha_val, random_state=2018))\n",
        "OVR.fit(xtrain,ytrain)\n",
        "\n",
        "Pred_OVR = OVR.predict(xtest)\n",
        "\n",
        "OVR_accuracy=accuracy_score(ytest,Pred_OVR)\n",
        "OVR_precision=precision_score(ytest,Pred_OVR,average='weighted')\n",
        "OVR_recall=recall_score(ytest,Pred_OVR,average='weighted')\n",
        "\n",
        "print(\"OVR Accuracy is: {}\".format(OVR_accuracy))\n",
        "print(\"OVR Precision is: {}\".format(OVR_precision))\n",
        "print(\"OVR Recall is: {}\".format(OVR_recall))\n",
        "#The accuracy, precision and recall seems a good result. they are all above 85%"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OVR Accuracy is: 0.8558201058201058\n",
            "OVR Precision is: 0.8592739760591119\n",
            "OVR Recall is: 0.8558201058201058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_8VxxxalxHU",
        "colab_type": "text"
      },
      "source": [
        "# 2.2 Choosing the best hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzm68ZtalxHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "minist_train, minist_test= train_test_split(minist, test_size=0.3)\n",
        "minist_test_y=minist_test['label']\n",
        "minist_test_x=minist_test.loc[:,'pixel0':'pixel783']\n",
        "minist_train_y=minist_train['label']\n",
        "minist_train_x=minist_train.loc[:,'pixel0':'pixel783']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hukm4PmnlxHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Choosing the best hyper parameter\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "def runOVRmodel(trials, train_data, penalty_type, penalty_score):\n",
        "\n",
        "   train_acc     = 0\n",
        "   val_acc       = 0\n",
        "   for i in range(0,trials):\n",
        "      Dtrain, Dtest,= train_test_split(train_data, test_size=0.3)\n",
        "      OVR = OneVsRestClassifier(LogisticRegression(C = 1/penalty_score,penalty=penalty_type,))\n",
        "      OVR.fit(Dtrain.iloc[:,1:785],Dtrain.iloc[:,0:1])\n",
        "      Pred_OVR_test = OVR.predict(minist_test_x)\n",
        "      Pred_OVR_train = OVR.predict(minist_train_x)\n",
        "      val_acc += accuracy_score(Pred_OVR_test, minist_test_y)\n",
        "      train_acc += accuracy_score(Pred_OVR_train, minist_train_y)\n",
        "   val_acc /= trials       \n",
        "   train_acc /= trials\n",
        "\n",
        "\n",
        "   return np.round(model_acc, decimals=2), np.round(val_acc,decimals=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPPMScFjlxHe",
        "colab_type": "code",
        "colab": {},
        "outputId": "8889345f-d214-44a8-e13e-34b5cdeefdc5"
      },
      "source": [
        "#Best Alpha\n",
        "alpha_vals = [0.1, 1, 3, 10, 33, 100, 333, 1000, 3333, 10000, 33333]\n",
        "\n",
        "Train_acc=np.zeros(len(alpha_vals))\n",
        "val_acc= np.zeros(len(alpha_vals))\n",
        "index = 0\n",
        "#L1 regularization\n",
        "for l in alpha_vals:\n",
        "    Train_acc[index],val_acc[index]   = runOVRmodel(10,train_data=minist_train,penalty_type='l1', penalty_score=np.float(l))\n",
        "    index += 1\n",
        "\n",
        "print(\"Train_Acc: {}\".format(Train_acc))\n",
        "print(\"Validation_Acc: {}\".format(val_acc))\n",
        "# penalty at which validation accuracy is maximum\n",
        "max_index_l1  = np.argmax(val_acc)\n",
        "best_alpha = alpha_vals[max_index_l1]\n",
        "print(\"Best Alpha: {}\".format(best_alpha))\n",
        "\n",
        "\n",
        "#plot the accuracy curve\n",
        "plt.plot(range(0,len(alpha_vals)), val_acc, color='b', \n",
        "         label='Validation Accuracy')\n",
        "plt.plot(range(0,len(alpha_vals)), Train_acc, color='r', \n",
        "         label='Training Accuracy')\n",
        "#replace the x-axis labels with penalty values\n",
        "plt.xticks(range(0,len(alpha_vals)), alpha_vals, rotation='vertical')\n",
        "\n",
        "#Highlight the best values of alpha\n",
        "plt.plot((max_index_l1, max_index_l1), (0, val_acc[max_index_l1]), \n",
        "         ls='dotted', color='b')\n",
        "\n",
        "\n",
        "#Set the y-axis from 0 to 1.0\n",
        "axes = plt.gca()\n",
        "axes.set_ylim([0, 1.0])\n",
        "\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.show()\n",
        "# With the training set it provides the same accuracy but with the validation set the accurcary seems to go down with alpha change\n",
        "#So according to validation accuracy the best alpha is 333 which provides the accuracy of 86%"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train_Acc: [0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95 0.95]\n",
            "Validation_Acc: [0.84 0.84 0.84 0.84 0.84 0.85 0.86 0.84 0.79 0.67 0.54]\n",
            "Best Alpha: 333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7vFXmmalxHk",
        "colab_type": "code",
        "colab": {},
        "outputId": "2cf1034e-1f08-4385-e2ca-53dcd30b22a8"
      },
      "source": [
        "#The final Model\n",
        "minist = pd.read_csv('reduced_mnist.csv', delimiter=',')\n",
        "Label=minist['label']\n",
        "Pexil=minist.loc[:,'pixel0':'pixel783']\n",
        "\n",
        "#split\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(Pexil, Label, test_size=0.3)\n",
        "\n",
        "alpha_val = 333\n",
        "\n",
        "OVR = OneVsRestClassifier(LogisticRegression(penalty='l1',C = 1/alpha_val, random_state=2018))\n",
        "OVR.fit(xtrain,ytrain)\n",
        "\n",
        "Predd_OVR = OVR.predict(xtest)\n",
        "\n",
        "OVR_accuracy=accuracy_score(ytest,Predd_OVR)\n",
        "OVR_precision=precision_score(ytest,Predd_OVR,average='weighted')\n",
        "OVR_recall=recall_score(ytest,Predd_OVR,average='weighted')\n",
        "OVR_Confusion_matrix= confusion_matrix(ytest,Predd_OVR)\n",
        "\n",
        "print(\"OVR Accuracy is: {}\".format(OVR_accuracy))\n",
        "print(\"OVR Precision is: {}\".format(OVR_precision))\n",
        "print(\"OVR Recall is: {}\".format(OVR_recall))\n",
        "print(\"OVR Confusion Matrix is:\\n{}\".format(OVR_Confusion_matrix))\n",
        "\n",
        "#The accuracy seems 88% and precision is also 88% it seems the model is a good fit, The model is not underfitting or overfitting"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OVR Accuracy is: 0.8875661375661376\n",
            "OVR Precision is: 0.8885642273417054\n",
            "OVR Recall is: 0.8875661375661376\n",
            "OVR Confusion Matrix is:\n",
            "[[72  0  1  0  0  0  0  0  0  0]\n",
            " [ 0 78  0  0  0  1  0  0  3  0]\n",
            " [ 0  0 62  1  1  0  3  3  8  0]\n",
            " [ 1  0  0 72  0  4  3  0  2  0]\n",
            " [ 0  0  0  0 63  0  0  1  1  1]\n",
            " [ 2  1  1  7  1 53  1  0  2  1]\n",
            " [ 2  1  1  0  0  1 76  0  1  0]\n",
            " [ 1  1  2  1  0  0  0 75  1  3]\n",
            " [ 0  2  1  2  0  4  0  0 59  2]\n",
            " [ 0  0  1  1  0  1  0  5  1 61]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqhF121blxHp",
        "colab_type": "code",
        "colab": {},
        "outputId": "0d0232d6-22a5-4867-9216-a022fdc59113"
      },
      "source": [
        "#top five feature selection in decreasing order\n",
        "\n",
        "feature_weights=OVR.coef_[0]\n",
        "Weight_matrix = pd.DataFrame()\n",
        "Weight_matrix['Feature'] = pd.Series(ytrain)\n",
        "Weight_matrix['Weights'] = pd.Series(feature_weights,name= \"Weights\")\n",
        "a= np.count_nonzero(Weight_matrix['Weights'])\n",
        "print(\"Number of Non zero features:{}\".format(a))\n",
        "#So, the number of non zero features is 1272."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Non zero features:1272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xndImuSklxHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}